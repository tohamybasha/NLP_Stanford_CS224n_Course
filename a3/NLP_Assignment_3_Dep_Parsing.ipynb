{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_Assignment#3_Dep_Parsing.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "bBgJjjyO2Gks",
        "colab_type": "code",
        "outputId": "ad0ae25a-30d7-4fab-beb9-e0380d81a991",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "!pip install tqdm"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (4.28.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SaWL-0YQHL3c",
        "colab_type": "code",
        "outputId": "6b41fc97-c0db-4908-9b73-f9b90a04c404",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "#!/usr/bin/env python3\n",
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "CS224N 2019-20: Homework 3\n",
        "parser_transitions.py: Algorithms for completing partial parsess.\n",
        "Sahil Chopra <schopra8@stanford.edu>\n",
        "Haoshen Hong <haoshen@stanford.edu>\n",
        "\"\"\"\n",
        "\n",
        "import sys\n",
        "\n",
        "class PartialParse(object):\n",
        "    def __init__(self, sentence):\n",
        "        \"\"\"Initializes this partial parse.\n",
        "\n",
        "        @param sentence (list of str): The sentence to be parsed as a list of words.\n",
        "                                        Your code should not modify the sentence.\n",
        "        \"\"\"\n",
        "        # The sentence being parsed is kept for bookkeeping purposes. Do not alter it in your code.\n",
        "        self.sentence = sentence\n",
        "\n",
        "        ### YOUR CODE HERE (3 Lines)\n",
        "        ### Your code should initialize the following fields:\n",
        "        ###     self.stack: The current stack represented as a list with the top of the stack as the\n",
        "        ###                 last element of the list.\n",
        "        ###     self.buffer: The current buffer represented as a list with the first item on the\n",
        "        ###                  buffer as the first item of the list\n",
        "        ###     self.dependencies: The list of dependencies produced so far. Represented as a list of\n",
        "        ###             tuples where each tuple is of the form (head, dependent).\n",
        "        ###             Order for this list doesn't matter.\n",
        "        ###\n",
        "        ### Note: The root token should be represented with the string \"ROOT\"\n",
        "        ###\n",
        "        self.stack = [\"ROOT\"]\n",
        "        self.buffer = list(sentence)\n",
        "        self.dependencies = []\n",
        "\n",
        "        ### END YOUR CODE\n",
        "\n",
        "\n",
        "    def parse_step(self, transition):\n",
        "        \"\"\"Performs a single parse step by applying the given transition to this partial parse\n",
        "\n",
        "        @param transition (str): A string that equals \"S\", \"LA\", or \"RA\" representing the shift,\n",
        "                                left-arc, and right-arc transitions. You can assume the provided\n",
        "                                transition is a legal transition.\n",
        "        \"\"\"\n",
        "        ### YOUR CODE HERE (~7-10 Lines)\n",
        "        ### TODO:\n",
        "        ###     Implement a single parsing step, i.e. the logic for the following as\n",
        "        ###     described in the pdf handout:\n",
        "        ###         1. Shift\n",
        "        ###         2. Left Arc\n",
        "        ###         3. Right Arc\n",
        "        if transition == \"S\":\n",
        "        # SHIFT : POP FIRST OF BUFFER AND INSERT IN STACK\n",
        "            self.stack.append(self.buffer.pop(0))\n",
        "        elif transition == \"LA\":\n",
        "            # Left-Arc : Top of stack is the head and second Top is the dependent & Remove the second top from stack & Keep the head\n",
        "            # Insert in dependencies list ( head, dependent )\n",
        "            self.dependencies.append((self.stack[-1], self.stack.pop(-2)))\n",
        "        elif transition == \"RA\":\n",
        "            # Right-Arc : Top of stack is the dependent and second Top is the head & Remove the first top from stack & Keep the head\n",
        "            self.dependencies.append((self.stack[-2], self.stack.pop()))\n",
        "\n",
        "        ### END YOUR CODE\n",
        "\n",
        "    def parse(self, transitions):\n",
        "        \"\"\"Applies the provided transitions to this PartialParse\n",
        "\n",
        "        @param transitions (list of str): The list of transitions in the order they should be applied\n",
        "\n",
        "        @return dsependencies (list of string tuples): The list of dependencies produced when\n",
        "                                                        parsing the sentence. Represented as a list of\n",
        "                                                        tuples where each tuple is of the form (head, dependent).\n",
        "        \"\"\"\n",
        "        for transition in transitions:\n",
        "            self.parse_step(transition)\n",
        "        return self.dependencies\n",
        "\n",
        "\n",
        "def minibatch_parse(sentences, model, batch_size):\n",
        "    \"\"\"Parses a list of sentences in minibatches using a model.\n",
        "\n",
        "    @param sentences (list of list of str): A list of sentences to be parsed\n",
        "                                            (each sentence is a list of words and each word is of type string)\n",
        "    @param model (ParserModel): The model that makes parsing decisions. It is assumed to have a function\n",
        "                                model.predict(partial_parses) that takes in a list of PartialParses as input and\n",
        "                                returns a list of transitions predicted for each parse. That is, after calling\n",
        "                                    transitions = model.predict(partial_parses)\n",
        "                                transitions[i] will be the next transition to apply to partial_parses[i].\n",
        "    @param batch_size (int): The number of PartialParses to include in each minibatch\n",
        "\n",
        "\n",
        "    @return dependencies (list of dependency lists): A list where each element is the dependencies\n",
        "                                                    list for a parsed sentence. Ordering should be the\n",
        "                                                    same as in sentences (i.e., dependencies[i] should\n",
        "                                                    contain the parse for sentences[i]).\n",
        "    \"\"\"\n",
        "    dependencies = []\n",
        "\n",
        "    ### YOUR CODE HERE (~8-10 Lines)\n",
        "    ### TODO:\n",
        "    ###     Implement the minibatch parse algorithm as described in the pdf handout\n",
        "    ###\n",
        "    ###     Note: A shallow copy (as denoted in the PDF) can be made with the \"=\" sign in python, e.g.\n",
        "    ###                 unfinished_parses = partial_parses[:].\n",
        "    ###             Here `unfinished_parses` is a shallow copy of `partial_parses`.\n",
        "    ###             In Python, a shallow copied list like `unfinished_parses` does not contain new instances\n",
        "    ###             of the object stored in `partial_parses`. Rather both lists refer to the same objects.\n",
        "    ###             In our case, `partial_parses` contains a list of partial parses. `unfinished_parses`\n",
        "    ###             contains references to the same objects. Thus, you should NOT use the `del` operator\n",
        "    ###             to remove objects from the `unfinished_parses` list. This will free the underlying memory that\n",
        "    ###             is being accessed by `partial_parses` and may cause your code to crash.\n",
        "\n",
        "    # Initialize partial parses as a list of PartialParses, one for each sentence in sentences\n",
        "    partial_parses  = [None]*len(sentences)\n",
        "    for i in range(len(sentences)):\n",
        "        partial_parses[i] = PartialParse(sentences[i])\n",
        "\n",
        "        \n",
        "    unfinished_parses = partial_parses[:]\n",
        "    while len(unfinished_parses) > 0:\n",
        "        batch = unfinished_parses[:batch_size]\n",
        "        transitions = model.predict(batch)\n",
        "        for parse_, trans in zip(batch, transitions):\n",
        "            parse_.parse_step(trans)\n",
        "            if len(parse_.buffer) == 0 and len(parse_.stack) ==1:\n",
        "                unfinished_parses.remove(parse_)\n",
        "\n",
        "    dependencies = [p.dependencies for p in partial_parses]\n",
        "    ### END YOUR CODE\n",
        "\n",
        "    return dependencies\n",
        "\n",
        "\n",
        "def test_step(name, transition, stack, buf, deps,\n",
        "              ex_stack, ex_buf, ex_deps):\n",
        "    \"\"\"Tests that a single parse step returns the expected output\"\"\"\n",
        "    pp = PartialParse([])\n",
        "    pp.stack, pp.buffer, pp.dependencies = stack, buf, deps\n",
        "\n",
        "    pp.parse_step(transition)\n",
        "    stack, buf, deps = (tuple(pp.stack), tuple(pp.buffer), tuple(sorted(pp.dependencies)))\n",
        "    assert stack == ex_stack, \\\n",
        "        \"{:} test resulted in stack {:}, expected {:}\".format(name, stack, ex_stack)\n",
        "    assert buf == ex_buf, \\\n",
        "        \"{:} test resulted in buffer {:}, expected {:}\".format(name, buf, ex_buf)\n",
        "    assert deps == ex_deps, \\\n",
        "        \"{:} test resulted in dependency list {:}, expected {:}\".format(name, deps, ex_deps)\n",
        "    print(\"{:} test passed!\".format(name))\n",
        "\n",
        "\n",
        "def test_parse_step():\n",
        "    \"\"\"Simple tests for the PartialParse.parse_step function\n",
        "    Warning: these are not exhaustive\n",
        "    \"\"\"\n",
        "    test_step(\"SHIFT\", \"S\", [\"ROOT\", \"the\"], [\"cat\", \"sat\"], [],\n",
        "              (\"ROOT\", \"the\", \"cat\"), (\"sat\",), ())\n",
        "    test_step(\"LEFT-ARC\", \"LA\", [\"ROOT\", \"the\", \"cat\"], [\"sat\"], [],\n",
        "              (\"ROOT\", \"cat\",), (\"sat\",), ((\"cat\", \"the\"),))\n",
        "    test_step(\"RIGHT-ARC\", \"RA\", [\"ROOT\", \"run\", \"fast\"], [], [],\n",
        "              (\"ROOT\", \"run\",), (), ((\"run\", \"fast\"),))\n",
        "\n",
        "\n",
        "def test_parse():\n",
        "    \"\"\"Simple tests for the PartialParse.parse function\n",
        "    Warning: these are not exhaustive\n",
        "    \"\"\"\n",
        "    sentence = [\"parse\", \"this\", \"sentence\"]\n",
        "    dependencies = PartialParse(sentence).parse([\"S\", \"S\", \"S\", \"LA\", \"RA\", \"RA\"])\n",
        "    dependencies = tuple(sorted(dependencies))\n",
        "    expected = (('ROOT', 'parse'), ('parse', 'sentence'), ('sentence', 'this'))\n",
        "    assert dependencies == expected,  \\\n",
        "        \"parse test resulted in dependencies {:}, expected {:}\".format(dependencies, expected)\n",
        "    assert tuple(sentence) == (\"parse\", \"this\", \"sentence\"), \\\n",
        "        \"parse test failed: the input sentence should not be modified\"\n",
        "    print(\"parse test passed!\")\n",
        "\n",
        "\n",
        "class DummyModel(object):\n",
        "    \"\"\"Dummy model for testing the minibatch_parse function\n",
        "    \"\"\"\n",
        "    def __init__(self, mode = \"unidirectional\"):\n",
        "        self.mode = mode\n",
        "\n",
        "    def predict(self, partial_parses):\n",
        "        if self.mode == \"unidirectional\":\n",
        "            return self.unidirectional_predict(partial_parses)\n",
        "        elif self.mode == \"interleave\":\n",
        "            return self.interleave_predict(partial_parses)\n",
        "        else:\n",
        "            raise NotImplementedError()\n",
        "\n",
        "    def unidirectional_predict(self, partial_parses):\n",
        "        \"\"\"First shifts everything onto the stack and then does exclusively right arcs if the first word of\n",
        "        the sentence is \"right\", \"left\" if otherwise.\n",
        "        \"\"\"\n",
        "        return [(\"RA\" if pp.stack[1] is \"right\" else \"LA\") if len(pp.buffer) == 0 else \"S\"\n",
        "                for pp in partial_parses]\n",
        "\n",
        "    def interleave_predict(self, partial_parses):\n",
        "        \"\"\"First shifts everything onto the stack and then interleaves \"right\" and \"left\".\n",
        "        \"\"\"\n",
        "        return [(\"RA\" if len(pp.stack) % 2 == 0 else \"LA\") if len(pp.buffer) == 0 else \"S\"\n",
        "                for pp in partial_parses]\n",
        "\n",
        "def test_dependencies(name, deps, ex_deps):\n",
        "    \"\"\"Tests the provided dependencies match the expected dependencies\"\"\"\n",
        "    deps = tuple(sorted(deps))\n",
        "    assert deps == ex_deps, \\\n",
        "        \"{:} test resulted in dependency list {:}, expected {:}\".format(name, deps, ex_deps)\n",
        "\n",
        "\n",
        "def test_minibatch_parse():\n",
        "    \"\"\"Simple tests for the minibatch_parse function\n",
        "    Warning: these are not exhaustive\n",
        "    \"\"\"\n",
        "\n",
        "    # Unidirectional arcs test\n",
        "    sentences = [[\"right\", \"arcs\", \"only\"],\n",
        "                 [\"right\", \"arcs\", \"only\", \"again\"],\n",
        "                 [\"left\", \"arcs\", \"only\"],\n",
        "                 [\"left\", \"arcs\", \"only\", \"again\"]]\n",
        "    deps = minibatch_parse(sentences, DummyModel(), 2)\n",
        "    test_dependencies(\"minibatch_parse\", deps[0],\n",
        "                      (('ROOT', 'right'), ('arcs', 'only'), ('right', 'arcs')))\n",
        "    test_dependencies(\"minibatch_parse\", deps[1],\n",
        "                      (('ROOT', 'right'), ('arcs', 'only'), ('only', 'again'), ('right', 'arcs')))\n",
        "    test_dependencies(\"minibatch_parse\", deps[2],\n",
        "                      (('only', 'ROOT'), ('only', 'arcs'), ('only', 'left')))\n",
        "    test_dependencies(\"minibatch_parse\", deps[3],\n",
        "                      (('again', 'ROOT'), ('again', 'arcs'), ('again', 'left'), ('again', 'only')))\n",
        "\n",
        "    # Out-of-bound test\n",
        "    sentences = [[\"right\"]]\n",
        "    deps = minibatch_parse(sentences, DummyModel(), 2)\n",
        "    test_dependencies(\"minibatch_parse\", deps[0], (('ROOT', 'right'),))\n",
        "\n",
        "    # Mixed arcs test\n",
        "    sentences = [[\"this\", \"is\", \"interleaving\", \"dependency\", \"test\"]]\n",
        "    deps = minibatch_parse(sentences, DummyModel(mode=\"interleave\"), 1)\n",
        "    test_dependencies(\"minibatch_parse\", deps[0],\n",
        "                      (('ROOT', 'is'), ('dependency', 'interleaving'),\n",
        "                      ('dependency', 'test'), ('is', 'dependency'), ('is', 'this')))\n",
        "    print(\"minibatch_parse test passed!\")\n",
        "\n",
        "\n",
        "'''if __name__ == '__main__':\n",
        "    args = sys.argv\n",
        "    if len(args) != 2:\n",
        "        raise Exception(\"You did not provide a valid keyword. Either provide 'part_c' or 'part_d', when executing this script\")\n",
        "    elif args[1] == \"part_c\":\n",
        "        test_parse_step()\n",
        "        test_parse()\n",
        "    elif args[1] == \"part_d\":\n",
        "        test_minibatch_parse()\n",
        "    else:\n",
        "        raise Exception(\"You did not provide a valid keyword. Either provide 'part_c' or 'part_d', when executing this script\")\n",
        "'''\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'if __name__ == \\'__main__\\':\\n    args = sys.argv\\n    if len(args) != 2:\\n        raise Exception(\"You did not provide a valid keyword. Either provide \\'part_c\\' or \\'part_d\\', when executing this script\")\\n    elif args[1] == \"part_c\":\\n        test_parse_step()\\n        test_parse()\\n    elif args[1] == \"part_d\":\\n        test_minibatch_parse()\\n    else:\\n        raise Exception(\"You did not provide a valid keyword. Either provide \\'part_c\\' or \\'part_d\\', when executing this script\")\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RMaqeqvdH1ca",
        "colab_type": "text"
      },
      "source": [
        "# (C)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LimgW6k6HQOz",
        "colab_type": "code",
        "outputId": "fa8e49cf-4600-4710-fbc8-8ad734a8a042",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "test_parse_step()\n",
        "test_parse()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SHIFT test passed!\n",
            "LEFT-ARC test passed!\n",
            "RIGHT-ARC test passed!\n",
            "parse test passed!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KaGxzqc7HpAE",
        "colab_type": "code",
        "outputId": "fe994198-2e36-4378-8d23-aaa6c192ec60",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "!python parser_transitions.py part_c"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SHIFT test passed!\n",
            "LEFT-ARC test passed!\n",
            "RIGHT-ARC test passed!\n",
            "parse test passed!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ddL5EUA6Syw_",
        "colab_type": "text"
      },
      "source": [
        "# (D)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uCBB9FUVH1lU",
        "colab_type": "code",
        "outputId": "49d3442b-42d6-453b-cb26-c2bb90bc931b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "test_minibatch_parse()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "minibatch_parse test passed!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vwJQmfhLUiyn",
        "colab_type": "text"
      },
      "source": [
        "# (E)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9i4vh5kfUkN6",
        "colab_type": "code",
        "outputId": "256eb789-ec51-4b62-81c8-de67b661b207",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "tt = nn.Parameter(nn.init.xavier_uniform_(torch.empty(2,5)))\n",
        "tt"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[-0.6069, -0.5430, -0.1276, -0.1830, -0.6857],\n",
              "        [-0.4782,  0.0298,  0.7539, -0.2688, -0.8564]], requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xYg1HfGBcF9t",
        "colab_type": "code",
        "outputId": "3ded2bd6-3b92-473c-8403-6ea1510f0c60",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "import numpy as np\n",
        "x = torch.randn(3, 4)\n",
        "indices = torch.tensor([0, 2])\n",
        "torch.index_select(x, 0, indices)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 2.1358,  1.4621, -0.5189, -0.7111],\n",
              "        [ 0.5240,  0.9194, -0.3916, -0.0295]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mN0o4ud3my8t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget http://web.stanford.edu/class/cs224n/assignments/a3.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S80fvJylxX4-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip a3.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UfiA5zaVxZSa",
        "colab_type": "code",
        "outputId": "5a2169ca-0e01-4ca6-da49-7a9af7a5ed95",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "%cd student\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/student\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "coLKNlYMxip6",
        "colab_type": "code",
        "outputId": "bd0150f9-bc0c-494f-ff91-60f5adedad5b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#Copied my code there\n",
        "!python parser_model.py -e"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Embedding_lookup sanity check passes!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ywol6OFCyFzL",
        "colab_type": "code",
        "outputId": "dd4656c8-34f4-4bed-9ab2-3ff6ffb6a3fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "!python parser_model.py -f"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Forward sanity check passes!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_tzTy6Oyo0i",
        "colab_type": "code",
        "outputId": "8847252e-8071-4171-8ce4-a1ac237d7092",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python run.py -d"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "INITIALIZING\n",
            "================================================================================\n",
            "Loading data...\n",
            "took 1.68 seconds\n",
            "Building parser...\n",
            "took 0.03 seconds\n",
            "Loading pretrained embeddings...\n",
            "took 1.91 seconds\n",
            "Vectorizing data...\n",
            "took 0.05 seconds\n",
            "Preprocessing training data...\n",
            "took 1.09 seconds\n",
            "took 0.00 seconds\n",
            "\n",
            "================================================================================\n",
            "TRAINING\n",
            "================================================================================\n",
            "Epoch 1 out of 10\n",
            "100% 48/48 [01:14<00:00,  1.15s/it]\n",
            "Average Train Loss: 0.5061016219357649\n",
            "Evaluating on dev set\n",
            "125250it [00:00, 16169177.47it/s]\n",
            "- dev UAS: 55.78\n",
            "New best dev UAS! Saving model.\n",
            "\n",
            "Epoch 2 out of 10\n",
            "100% 48/48 [01:15<00:00,  1.17s/it]\n",
            "Average Train Loss: 0.26751851042111713\n",
            "Evaluating on dev set\n",
            "125250it [00:00, 17784507.80it/s]\n",
            "- dev UAS: 59.72\n",
            "New best dev UAS! Saving model.\n",
            "\n",
            "Epoch 3 out of 10\n",
            "100% 48/48 [01:13<00:00,  1.15s/it]\n",
            "Average Train Loss: 0.2212474038824439\n",
            "Evaluating on dev set\n",
            "125250it [00:00, 17567434.99it/s]\n",
            "- dev UAS: 62.83\n",
            "New best dev UAS! Saving model.\n",
            "\n",
            "Epoch 4 out of 10\n",
            "100% 48/48 [01:12<00:00,  1.14s/it]\n",
            "Average Train Loss: 0.18796728768696389\n",
            "Evaluating on dev set\n",
            "125250it [00:00, 18152611.47it/s]\n",
            "- dev UAS: 63.57\n",
            "New best dev UAS! Saving model.\n",
            "\n",
            "Epoch 5 out of 10\n",
            "100% 48/48 [01:13<00:00,  1.16s/it]\n",
            "Average Train Loss: 0.17037683663268885\n",
            "Evaluating on dev set\n",
            "125250it [00:00, 16752338.28it/s]\n",
            "- dev UAS: 65.53\n",
            "New best dev UAS! Saving model.\n",
            "\n",
            "Epoch 6 out of 10\n",
            "100% 48/48 [01:13<00:00,  1.16s/it]\n",
            "Average Train Loss: 0.1444987365975976\n",
            "Evaluating on dev set\n",
            "125250it [00:00, 14010096.17it/s]\n",
            "- dev UAS: 66.58\n",
            "New best dev UAS! Saving model.\n",
            "\n",
            "Epoch 7 out of 10\n",
            "100% 48/48 [01:13<00:00,  1.13s/it]\n",
            "Average Train Loss: 0.12639158808936676\n",
            "Evaluating on dev set\n",
            "125250it [00:00, 17863122.72it/s]\n",
            "- dev UAS: 68.32\n",
            "New best dev UAS! Saving model.\n",
            "\n",
            "Epoch 8 out of 10\n",
            "100% 48/48 [01:13<00:00,  1.13s/it]\n",
            "Average Train Loss: 0.11209241300821304\n",
            "Evaluating on dev set\n",
            "125250it [00:00, 17426410.67it/s]\n",
            "- dev UAS: 68.93\n",
            "New best dev UAS! Saving model.\n",
            "\n",
            "Epoch 9 out of 10\n",
            "100% 48/48 [01:12<00:00,  1.13s/it]\n",
            "Average Train Loss: 0.10039162620281179\n",
            "Evaluating on dev set\n",
            "125250it [00:00, 17740665.14it/s]\n",
            "- dev UAS: 69.63\n",
            "New best dev UAS! Saving model.\n",
            "\n",
            "Epoch 10 out of 10\n",
            "100% 48/48 [01:12<00:00,  1.13s/it]\n",
            "Average Train Loss: 0.09065668269370993\n",
            "Evaluating on dev set\n",
            "125250it [00:00, 17861907.99it/s]\n",
            "- dev UAS: 69.73\n",
            "New best dev UAS! Saving model.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X1rbNnxdzSmq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "be6b37be-da8b-4fdc-c139-de8c31f0fba6"
      },
      "source": [
        "!python run.py"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "INITIALIZING\n",
            "================================================================================\n",
            "Loading data...\n",
            "took 1.60 seconds\n",
            "Building parser...\n",
            "took 1.24 seconds\n",
            "Loading pretrained embeddings...\n",
            "took 2.14 seconds\n",
            "Vectorizing data...\n",
            "took 1.54 seconds\n",
            "Preprocessing training data...\n",
            "took 35.76 seconds\n",
            "took 0.01 seconds\n",
            "\n",
            "================================================================================\n",
            "TRAINING\n",
            "================================================================================\n",
            "Epoch 1 out of 10\n",
            "100% 1848/1848 [06:25<00:00,  4.88it/s]\n",
            "Average Train Loss: 0.15452668404214698\n",
            "Evaluating on dev set\n",
            "1445850it [00:00, 54827763.51it/s]\n",
            "- dev UAS: 83.83\n",
            "New best dev UAS! Saving model.\n",
            "\n",
            "Epoch 2 out of 10\n",
            "100% 1848/1848 [06:26<00:00,  4.89it/s]\n",
            "Average Train Loss: 0.09556062513905944\n",
            "Evaluating on dev set\n",
            "1445850it [00:00, 57528738.48it/s]\n",
            "- dev UAS: 85.94\n",
            "New best dev UAS! Saving model.\n",
            "\n",
            "Epoch 3 out of 10\n",
            "100% 1848/1848 [06:21<00:00,  4.77it/s]\n",
            "Average Train Loss: 0.08250963118620765\n",
            "Evaluating on dev set\n",
            "1445850it [00:00, 56581367.98it/s]\n",
            "- dev UAS: 86.76\n",
            "New best dev UAS! Saving model.\n",
            "\n",
            "Epoch 4 out of 10\n",
            "100% 1848/1848 [06:19<00:00,  4.80it/s]\n",
            "Average Train Loss: 0.074705859138207\n",
            "Evaluating on dev set\n",
            "1445850it [00:00, 57842605.43it/s]\n",
            "- dev UAS: 87.24\n",
            "New best dev UAS! Saving model.\n",
            "\n",
            "Epoch 5 out of 10\n",
            "100% 1848/1848 [06:20<00:00,  4.94it/s]\n",
            "Average Train Loss: 0.06904732988687692\n",
            "Evaluating on dev set\n",
            "1445850it [00:00, 57443184.57it/s]\n",
            "- dev UAS: 86.69\n",
            "\n",
            "Epoch 6 out of 10\n",
            "100% 1848/1848 [06:20<00:00,  4.96it/s]\n",
            "Average Train Loss: 0.06441099757885003\n",
            "Evaluating on dev set\n",
            "1445850it [00:00, 54553533.45it/s]\n",
            "- dev UAS: 87.65\n",
            "New best dev UAS! Saving model.\n",
            "\n",
            "Epoch 7 out of 10\n",
            "100% 1848/1848 [06:24<00:00,  4.90it/s]\n",
            "Average Train Loss: 0.06027286627442774\n",
            "Evaluating on dev set\n",
            "1445850it [00:00, 57709398.56it/s]\n",
            "- dev UAS: 87.68\n",
            "New best dev UAS! Saving model.\n",
            "\n",
            "Epoch 8 out of 10\n",
            "100% 1848/1848 [06:21<00:00,  4.94it/s]\n",
            "Average Train Loss: 0.05708603906743551\n",
            "Evaluating on dev set\n",
            "1445850it [00:00, 57104573.94it/s]\n",
            "- dev UAS: 87.58\n",
            "\n",
            "Epoch 9 out of 10\n",
            "100% 1848/1848 [06:27<00:00,  4.70it/s]\n",
            "Average Train Loss: 0.054008268840909326\n",
            "Evaluating on dev set\n",
            "1445850it [00:00, 56514402.16it/s]\n",
            "- dev UAS: 87.67\n",
            "\n",
            "Epoch 10 out of 10\n",
            "100% 1848/1848 [06:35<00:00,  4.91it/s]\n",
            "Average Train Loss: 0.05130125177939507\n",
            "Evaluating on dev set\n",
            "1445850it [00:00, 45113815.63it/s]\n",
            "- dev UAS: 87.28\n",
            "\n",
            "================================================================================\n",
            "TESTING\n",
            "================================================================================\n",
            "Restoring the best model weights found on the dev set\n",
            "Final evaluation on test set\n",
            "2919736it [00:00, 76943562.00it/s]\n",
            "- test UAS: 87.86\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3eSennkh-cxK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "aff31983-e17b-44ff-e422-33c063dadbd8"
      },
      "source": [
        "!python run.py -d"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "INITIALIZING\n",
            "================================================================================\n",
            "Loading data...\n",
            "took 1.73 seconds\n",
            "Building parser...\n",
            "took 0.03 seconds\n",
            "Loading pretrained embeddings...\n",
            "took 1.97 seconds\n",
            "Vectorizing data...\n",
            "took 0.05 seconds\n",
            "Preprocessing training data...\n",
            "took 1.08 seconds\n",
            "took 0.00 seconds\n",
            "\n",
            "================================================================================\n",
            "TRAINING\n",
            "================================================================================\n",
            "Epoch 1 out of 10\n",
            "100% 48/48 [00:10<00:00,  4.70it/s]\n",
            "Average Train Loss: 0.6258880458772182\n",
            "Evaluating on dev set\n",
            "125250it [00:00, 16115607.58it/s]\n",
            "- dev UAS: 54.73\n",
            "New best dev UAS! Saving model.\n",
            "\n",
            "Epoch 2 out of 10\n",
            "100% 48/48 [00:10<00:00,  4.66it/s]\n",
            "Average Train Loss: 0.29806734931965667\n",
            "Evaluating on dev set\n",
            "125250it [00:00, 13111452.72it/s]\n",
            "- dev UAS: 59.62\n",
            "New best dev UAS! Saving model.\n",
            "\n",
            "Epoch 3 out of 10\n",
            "100% 48/48 [00:10<00:00,  4.70it/s]\n",
            "Average Train Loss: 0.24989545562614998\n",
            "Evaluating on dev set\n",
            "125250it [00:00, 16402928.03it/s]\n",
            "- dev UAS: 62.48\n",
            "New best dev UAS! Saving model.\n",
            "\n",
            "Epoch 4 out of 10\n",
            "100% 48/48 [00:10<00:00,  4.69it/s]\n",
            "Average Train Loss: 0.21980773533384004\n",
            "Evaluating on dev set\n",
            "125250it [00:00, 13717075.98it/s]\n",
            "- dev UAS: 64.28\n",
            "New best dev UAS! Saving model.\n",
            "\n",
            "Epoch 5 out of 10\n",
            "100% 48/48 [00:10<00:00,  4.75it/s]\n",
            "Average Train Loss: 0.19735221285372972\n",
            "Evaluating on dev set\n",
            "125250it [00:00, 15748915.55it/s]\n",
            "- dev UAS: 66.80\n",
            "New best dev UAS! Saving model.\n",
            "\n",
            "Epoch 6 out of 10\n",
            "100% 48/48 [00:10<00:00,  4.71it/s]\n",
            "Average Train Loss: 0.1780736387396852\n",
            "Evaluating on dev set\n",
            "125250it [00:00, 16110171.30it/s]\n",
            "- dev UAS: 68.72\n",
            "New best dev UAS! Saving model.\n",
            "\n",
            "Epoch 7 out of 10\n",
            "100% 48/48 [00:10<00:00,  4.67it/s]\n",
            "Average Train Loss: 0.16001585125923157\n",
            "Evaluating on dev set\n",
            "125250it [00:00, 15778242.26it/s]\n",
            "- dev UAS: 69.52\n",
            "New best dev UAS! Saving model.\n",
            "\n",
            "Epoch 8 out of 10\n",
            "100% 48/48 [00:10<00:00,  4.74it/s]\n",
            "Average Train Loss: 0.1468095692495505\n",
            "Evaluating on dev set\n",
            "125250it [00:00, 15716405.67it/s]\n",
            "- dev UAS: 70.17\n",
            "New best dev UAS! Saving model.\n",
            "\n",
            "Epoch 9 out of 10\n",
            "100% 48/48 [00:10<00:00,  4.69it/s]\n",
            "Average Train Loss: 0.13422163156792521\n",
            "Evaluating on dev set\n",
            "125250it [00:00, 16238650.30it/s]\n",
            "- dev UAS: 71.68\n",
            "New best dev UAS! Saving model.\n",
            "\n",
            "Epoch 10 out of 10\n",
            "100% 48/48 [00:10<00:00,  4.70it/s]\n",
            "Average Train Loss: 0.12095943621049325\n",
            "Evaluating on dev set\n",
            "125250it [00:00, 15620605.27it/s]\n",
            "- dev UAS: 71.99\n",
            "New best dev UAS! Saving model.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJ2wlfmZAIjx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}